ISupervised Learning involves training a model using labeled data.

https://media.geeksforgeeks.org/wp-content/uploads/20241022160725494723/supervised-machine-learning.webp

Types of Supervised Learning in Machine Learning
Now, Supervised learning can be applied to two main types of problems:
By determining the output supervised learning technique divided into two types:

1. Classification:  (words)
      Where the output is a categorical variable (e.g., spam vs. non-spam emails, yes vs. no).
      Tow or more than two 
2. Regression: (Numbers)
      Where the output is a continuous variable (e.g., predicting house prices, stock prices).

https://media.geeksforgeeks.org/wp-content/uploads/supervised-data.png

01. Classification
Classification deals with predicting categorical target variables, which represent discrete classes or labels. 
For instance, classifying emails as spam or not spam, or predicting whether a patient has a high risk of heart disease. 
Classification algorithms learn to map the input features to one of the predefined classes.

Here are some classification algorithms:

1. Logistic Regression
2. Support Vector Machine
3. Random Forest
4. Decision Tree 
5. K-Nearest Neighbors (KNN)
6. Naive Bayes


02. Regression:

Regression, on the other hand, deals with predicting continuous target variables, which represent numerical values. 
For example, predicting the price of a house based on its size, location, and amenities, or forecasting the sales of a product. 
Regression algorithms learn to map the input features to a continuous numerical value.

Here are some regression algorithms:

1. Linear Regression
2. Polynomial Regression
3. Ridge Regression
4. Lasso Regression
5. Decision tree
6. Random Forest

Advantages of Supervised Machine Learning:
-> Supervised Learning models can have high accuracy as they are trained on labelled data.
-> The process of decision-making in supervised learning models is often interpretable.
-> It can often be used in pre-trained models which saves time and resources when developing new models from scratch.
Disadvantages of Supervised Machine Learning:
-> It has limitations in knowing patterns and may struggle with unseen or unexpected patterns that are not present in the training data.
-> It can be time-consuming and costly as it relies on labeled data only.
-> It may lead to poor generalizations based on new data.

Applications of Supervised Learning:
Supervised learning is used in a wide variety of applications, including:

Image classification: Identify objects, faces, and other features in images.
Natural language processing: Extract information from text, such as sentiment, entities, and relationships.
Speech recognition: Convert spoken language into text.
Recommendation systems: Make personalized recommendations to users.
Predictive analytics: Predict outcomes, such as sales, customer churn, and stock prices.
Medical diagnosis: Detect diseases and other medical conditions.
Fraud detection: Identify fraudulent transactions.
Autonomous vehicles: Recognize and respond to objects in the environment.
Email spam detection: Classify emails as spam or not spam.
Quality control in manufacturing: Inspect products for defects.
Credit scoring: Assess the risk of a borrower defaulting on a loan.
Gaming: Recognize characters, analyze player behavior, and create NPCs.
Customer support: Automate customer support tasks.
Weather forecasting: Make predictions for temperature, precipitation, and other meteorological parameters.
Sports analytics: Analyze player performance, make game predictions, and optimize strategies.




Let’s summarize the supervised machine learning algorithms in table:

Algorithm	                Regression,                 Purpose	                        Method	                                                   Use Cases
                                Classification	               

01. Linear Regression	        Regression	       Predict continuous                 1. Linear equation                                           Predicting continuous values
                                                        output values	                  2. minimizing sum of squares of residuals	      

02. Logistic Regression	        Classification	        Predict binary                    1.  Logistic function                                         Binary classification tasks
                                                        output variable	                  2. transforming linear relationship	        

03. Decision Trees	           Both	                Model decisions                    Tree-like structure with decisions 	                         Classification and Regression tasks 
                                                        and outcomes	                        and outcomes

04. Random Forests	           Both                	Improve classification                 Combining multiple decision trees                           1. Reducing overfitting,
                                                        and regression accuracy                 	                                                2. improving prediction accuracy

05. SVM	                           Both                	Create hyperplane for                  1.  Maximizing margin                                         Classification and Regression tasks
                                                        classification                         between classes or 
                                                        or predict continuous values	       2. predicting continuous values

06. KNN	                           Both	                Predict class or                    1. Finding k closest neighbors and                              1.   Classification and Regression tasks, 
                                                        value based on                      2. predicting based on majority or average                        2. sensitive to noisy data
                                                        k closest neighbors		

07. Gradient Boosting	          Both               	Combine weak learners to                 Iteratively correcting errors                             1. Classification and Regression tasks
                                                        create strong model		               with new models                                         to improve prediction accuracy

08. Naive Bayes	                Classification        	Predict class based on                 Bayes’ theorem with feature                                   1. Text classification,
                                                        feature independence assumption	           independence assumption 	                             2.  spam filtering,  
                                                                                                                                                             3.  sentiment analysis,
                                                                                                                                                             4.  medical
